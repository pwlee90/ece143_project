{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Music Popularity Prediction\n",
    "**ECE 143**\n",
    "\n",
    "**Peng Wei Lee, Karrmanya Pande, Yue Yu, Henri Schulz, Karl Hernandez**\n",
    "\n",
    "## Table of Contents\n",
    "1. Introduction\n",
    "2. Datasets\n",
    "3. Data Cleaning\n",
    "4. Exploratory Data Analysis\n",
    "5. Metric Selection\n",
    "6. Model Building\n",
    "7. Model Evaluation\n",
    "8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "- Brief description of the project\n",
    "- Objectives and goals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datasets\n",
    "**data1 : [Top 100 Songs & Lyrics By Year 1959 - 2023 (USA)](https://www.kaggle.com/datasets/brianblakely/top-100-songs-and-lyrics-from-1959-to-2019)**\n",
    "- Description:\n",
    "    - TODO\n",
    "- Relevant Features:\n",
    "    - artist, lyrics, rank, release date, song title, year, verbs, nouns, adverb, corpus, word count, unique word count\n",
    "- Irrelevant features:\n",
    "    - featured artist, media, url, writers, album, album url\n",
    "- Selected Files:\n",
    "    - [all_songs_data.csv](./data/data1.csv)\n",
    "\n",
    "**data2 : [MusicOSet Popularity](https://marianaossilva.github.io/DSW2019/?utm_source=chatgpt.com#tables)**\n",
    "- Description:\n",
    "    - TODO\n",
    "- Relevant Features:\n",
    "    - song name, artist, popularity, song type\n",
    "- Irrelevant features:\n",
    "    - song_id, explicit, key of artist dictionary, billboard\n",
    "- Selected Files:\n",
    "    - [musicOset_popularity/song_chart.csv](./data/data2.csv)\n",
    "\n",
    "**data3 : [SpotGenTrack Popularity Dataset](https://data.mendeley.com/datasets/4m2x4zngny/1)**\n",
    "- Description:\n",
    "    - TODO\n",
    "- Relevant Features:\n",
    "    - acoustics, available markets, danceability, duration, energy, instrumentalness, key, liveness, loudness, lyrics, name, popularity, speechness, tempo, time signature, valence\n",
    "- Irrelevant features:\n",
    "    - serial number, album id, analysis url, artist id, disk number, href, id, mode, playlist, preview url, track_href, track name prev, track number, uri, type\n",
    "- Selected Files:\n",
    "    - [SpotGenTrack/Data Sources/spotify_tracks.csv](./data/data3.csv)\n",
    "\n",
    "**data4 : [Spotify and Youtube Statistics](https://www.kaggle.com/datasets/salvatorerastelli/spotify-and-youtube)**\n",
    "- Description:\n",
    "    - TODO\n",
    "- Relevant Features:\n",
    "    - artist, track, danceability, energy, key, loudness, speechness, acoustics,instrumentalness, liveness, valence, tempo, duration, views, likes, comments, streams\n",
    "- Irrelevant Features:\n",
    "    - url_spotify, album, album type, url, url_youtube, title, channel, description, licensed, official_video\n",
    "- Selected Files:\n",
    "    - [Spotify_Youtube.csv](./data/data4.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "\n",
    "First, we will install all necessary requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qr requirements.txt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will delete all columns that are not of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_files/data1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlbum\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlbum URL\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatured Artists\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSong URL\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWriters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_files/new_data1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdelete_data_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_to_drop\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_files/data3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malbum_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalysis_url\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martists_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisc_number\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplaylist\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreview_url\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_href\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_name_prev\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_number\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalence\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mdelete_data_columns\u001b[1;34m(file, columns_to_drop, new_file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdelete_data_columns\u001b[39m(file:\u001b[38;5;28mstr\u001b[39m, columns_to_drop:\u001b[38;5;28mlist\u001b[39m, new_file:\u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Load the CSV file into a DataFrame\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Save the updated DataFrame back to a CSV file (if you want to overwrite it or create a new one)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\henri\\OneDrive\\Documents\\ECE143\\ece143_project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henri\\OneDrive\\Documents\\ECE143\\ece143_project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\henri\\OneDrive\\Documents\\ECE143\\ece143_project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henri\\OneDrive\\Documents\\ECE143\\ece143_project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\henri\\OneDrive\\Documents\\ECE143\\ece143_project\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_files/data1.csv'"
     ]
    }
   ],
   "source": [
    "def delete_data_columns(file:str, columns_to_drop:list, new_file:str):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Save the updated DataFrame back to a CSV file (if you want to overwrite it or create a new one)\n",
    "    df.to_csv(new_file, index=False)\n",
    "    print(df)\n",
    "\n",
    "file = 'data_files/data1.csv'\n",
    "columns_to_drop = ['Album','Album URL','Featured Artists','Media','Song URL','Writers']\n",
    "new_file = 'data_files/new_data1.csv'\n",
    "delete_data_columns(file, columns_to_drop,new_file)\n",
    "file = 'data_files/data3.csv'\n",
    "columns_to_drop = ['album_id','analysis_url','artists_id','disc_number','href','id','playlist','preview_url','track_href','track_name_prev','track_number','uri','valence']\n",
    "new_file = 'data_files/new_data3.csv'\n",
    "delete_data_columns(file, columns_to_drop,new_file)\n",
    "file = 'data_files/data4.csv'\n",
    "columns_to_drop = ['Url_spotify','Track','Album','Album_type','Uri','Valence','Url_youtube','Channel','Licensed','official_video']\n",
    "new_file = 'data_files/new_data4.csv'\n",
    "delete_data_columns(file, columns_to_drop,new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply some transforms \n",
    "\n",
    "TODO Explain more and correct code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Karmanya Pandey/Desktop/UCSD/Winter Quarter 24/ECE 143/Project/data_files/new_data4_updated.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# New CSV file with the popularity column\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Call the function to add the popularity column\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43madd_popularity_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m, in \u001b[0;36madd_popularity_column\u001b[1;34m(input_file, output_file, weight_views, weight_likes)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_popularity_column\u001b[39m(input_file, output_file, weight_views\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, weight_likes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(input_file)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Drop rows where both Views and Likes are missing or NaN\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mViews\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLikes\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "def log_popularity(views, likes):\n",
    "    # Apply logarithmic scaling to views and likes\n",
    "    log_views = np.log1p(views)  # log1p ensures that log(0) is handled\n",
    "    log_likes = np.log1p(likes)\n",
    "    \n",
    "    # Combine them (e.g., average of log-transformed values)\n",
    "    combined_log = [(lv + ll) / 2 for lv, ll in zip(log_views, log_likes)]\n",
    "    \n",
    "    # Normalize the combined log scores to a range between 5 and 95\n",
    "    min_log = np.min(combined_log)\n",
    "    max_log = np.max(combined_log)\n",
    "    popularity = [(95 - 5) * (score - min_log) / (max_log - min_log) + 5 for score in combined_log]\n",
    "    popularity = [floor(score) for score in popularity]\n",
    "    return popularity\n",
    "\n",
    "# Function to read the CSV, calculate popularity, remove description column, and save the updated CSV\n",
    "def add_popularity_column(input_file, output_file, weight_views=0.3, weight_likes=0.7):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Drop rows where both Views and Likes are missing or NaN\n",
    "    df = df.dropna(subset=['Views', 'Likes'], how='all')\n",
    "\n",
    "    # Set Likes = 0 if Views is present but Likes is missing\n",
    "    df['Likes'] = df.apply(lambda row: 0 if pd.isna(row['Likes']) else row['Likes'], axis=1)\n",
    "    \n",
    "    # Set Views = Likes if only Likes is present (i.e., Views is missing)\n",
    "    df['Views'] = df.apply(lambda row: row['Likes'] if pd.isna(row['Views']) else row['Views'], axis=1)\n",
    "\n",
    "    # Drop the 'Description' column if it exists\n",
    "    if 'Description' in df.columns:\n",
    "        df = df.drop(columns=['Description'])\n",
    "    \n",
    "    # Extract Views and Likes columns\n",
    "    views = df['Views'].tolist()\n",
    "    likes = df['Likes'].tolist()\n",
    "\n",
    "    # Calculate the popularity score\n",
    "    popularity_scores = log_popularity(views, likes)\n",
    "    \n",
    "    # Add popularity as a new column to the dataframe\n",
    "    df['Popularity'] = popularity_scores\n",
    "    \n",
    "    # Save the updated dataframe to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Example usage\n",
    "input_file = 'C:/Users/Karmanya Pandey/Desktop/UCSD/Winter Quarter 24/ECE 143/Project/data_files/new_data4.csv'  # Your input CSV file name\n",
    "output_file = 'C:/Users/Karmanya Pandey/Desktop/UCSD/Winter Quarter 24/ECE 143/Project/data_files/new_data4_updated.csv'  # New CSV file with the popularity column\n",
    "\n",
    "# Call the function to add the popularity column\n",
    "add_popularity_column(input_file, output_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data in usable forms, we will merge them all into a singular combined dataset\n",
    "\n",
    "TODO: Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "file1 = pd.read_csv(\"./data/new_data1_updated.csv\")\n",
    "file2 = pd.read_csv(\"./data/new_data2_updated.csv\")\n",
    "file3 = pd.read_csv(\"./data/new_data3_updated.csv\")\n",
    "file4 = pd.read_csv(\"./data/new_data4_updated.csv\")\n",
    "\n",
    "# Rename columns to make them consistent across all files\n",
    "#file4.rename(columns={'Track': 'song_name'}, inplace=True)\n",
    "file2.rename(columns={'artists': 'Artist', 'song_type': 'Song_type'}, inplace=True)\n",
    "#file1.rename(columns={'Song Title': 'song_name'}, inplace=True)\n",
    "file3.rename(columns={'acousticness': 'Acousticness', 'available_markets': 'Available_markets', 'lyrics': 'Lyrics', 'country': 'Country','danceability': 'Danceability', 'duration_ms': 'Duration_ms', 'instrumentalness': 'Instrumentalness', 'key': 'Key', 'liveness': 'Liveness', 'loudness': 'Loudness', 'mode': 'Mode', 'speechiness': 'Speechiness', 'tempo': 'Tempo', 'time_signature': 'Time_signature', 'type': 'Song_type'}, inplace=True)\n",
    "# Merge all the files on the common columns\n",
    "merged_df = pd.concat([file1, file2, file3, file4], axis=0, ignore_index=True)\n",
    "\n",
    "# Combine columns 'song_name', 'name', 'Track', 'Song Title' into one column\n",
    "merged_df['song_name'] = merged_df[['song_name', 'name', 'Track', 'Song Title']].bfill(axis=1).iloc[:, 0]\n",
    "merged_df.drop(columns=['name', 'Track', 'Song Title'], inplace=True)\n",
    "\n",
    "merged_df['Popularity'] = merged_df[['Popularity', 'popularity']].bfill(axis=1).iloc[:, 0]\n",
    "merged_df.drop(columns=['popularity'], inplace=True)\n",
    "\n",
    "# Group by 'song_name' and aggregate by filling NaN values with the available data\n",
    "merged_df = merged_df.groupby('song_name', as_index=False).first()\n",
    "\n",
    "# Now you can save the merged CSV file\n",
    "merged_df.to_csv('./data/combine_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to remove all songs that don't have a popularity ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('./data/combine_all.csv')\n",
    "\n",
    "combined_data.dropna(subset=['Popularity'], how='all', inplace=True) # Drop rows where popluarity is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "First, we will examine the correlation between each of the numerical features and the popularity of the music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance between Year and popularity: -0.01407080251472065\n",
      "Covariance between Word Counts and popularity: 0.03831517810486524\n",
      "Covariance between Unique Word Counts and popularity: 0.006039466470777727\n",
      "Covariance between Popularity and popularity: 1.0\n",
      "Covariance between Acousticness and popularity: -0.16589369041845256\n",
      "Covariance between Danceability and popularity: 0.11603385786375445\n",
      "Covariance between Duration_ms and popularity: -0.15399315891181292\n",
      "Covariance between energy and popularity: 0.15248208099437377\n",
      "Covariance between Instrumentalness and popularity: -0.08047229472534666\n",
      "Covariance between Key and popularity: 0.0037347458959941277\n",
      "Covariance between Liveness and popularity: -0.04899295793622858\n",
      "Covariance between Loudness and popularity: 0.2481900521059149\n",
      "Covariance between Speechiness and popularity: -0.27416947038327116\n",
      "Covariance between Tempo and popularity: 0.0744188021646983\n",
      "Covariance between Time_signature and popularity: 0.11628466486956997\n",
      "Covariance between Energy and popularity: 0.1147456025946196\n",
      "Covariance between Valence and popularity: 0.05435978030803671\n",
      "Covariance between Views and popularity: 0.2604066750560871\n",
      "Covariance between Likes and popularity: 0.2899162464856268\n",
      "Covariance between Comments and popularity: 0.15058681843981225\n",
      "Covariance between Stream and popularity: 0.29281616698585494\n"
     ]
    }
   ],
   "source": [
    "def compute_correlation(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Computes the covariance between two columns in a DataFrame.\n",
    "    \"\"\"\n",
    "    return df[col1].dropna().corr(df[col2])\n",
    "\n",
    "numeric_columns = combined_data.select_dtypes(include=['number']).columns\n",
    "for col in numeric_columns:\n",
    "        print(f\"Covariance between {col} and popularity: {compute_correlation(combined_data, col, 'Popularity')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Implement evaluation of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Apply to all categorical variables\u001b[39;00m\n\u001b[0;32m     21\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m combined_data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m---> 22\u001b[0m eta_squared_results \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrelation_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPopularity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Display sorted results\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mSeries(eta_squared_results)\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "Cell \u001b[1;32mIn[36], line 22\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Apply to all categorical variables\u001b[39;00m\n\u001b[0;32m     21\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m combined_data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m---> 22\u001b[0m eta_squared_results \u001b[38;5;241m=\u001b[39m {col: \u001b[43mcorrelation_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPopularity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols}\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Display sorted results\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mSeries(eta_squared_results)\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "Cell \u001b[1;32mIn[36], line 12\u001b[0m, in \u001b[0;36mcorrelation_ratio\u001b[1;34m(categories, values)\u001b[0m\n\u001b[0;32m      9\u001b[0m overall_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(values)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compute between-group variance\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m between_group_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moverall_mean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43munique_categories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Compute total variance\u001b[39;00m\n\u001b[0;32m     16\u001b[0m total_var \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((values \u001b[38;5;241m-\u001b[39m overall_mean) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[36], line 12\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m overall_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(values)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compute between-group variance\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m between_group_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(values[categories \u001b[38;5;241m==\u001b[39m cat]) \u001b[38;5;241m*\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m-\u001b[39m overall_mean)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \n\u001b[0;32m     13\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m unique_categories)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Compute total variance\u001b[39;00m\n\u001b[0;32m     16\u001b[0m total_var \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((values \u001b[38;5;241m-\u001b[39m overall_mean) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\henri\\OneDrive\\Documents\\ECE143\\ece143_project\\venv\\Lib\\site-packages\\pandas\\core\\series.py:1151\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[0;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_rows_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_with(key)\n",
      "File \u001b[1;32mc:\\Users\\henri\\OneDrive\\Documents\\ECE143\\ece143_project\\venv\\Lib\\site-packages\\pandas\\core\\series.py:1217\u001b[0m, in \u001b[0;36mSeries._get_rows_with_mask\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_rows_with_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, indexer: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 1217\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rows_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\henri\\OneDrive\\Documents\\ECE143\\ece143_project\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1968\u001b[0m, in \u001b[0;36mSingleBlockManager.get_rows_with_mask\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   1964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;66;03m# TODO(CoW) in theory only need to track reference if new_array is a view\u001b[39;00m\n\u001b[0;32m   1966\u001b[0m     refs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mrefs\n\u001b[1;32m-> 1968\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1969\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(blk)(array, placement\u001b[38;5;241m=\u001b[39mbp, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, refs\u001b[38;5;241m=\u001b[39mrefs)\n\u001b[0;32m   1971\u001b[0m new_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex[indexer]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def correlation_ratio(categories, values):\n",
    "    \"\"\"\n",
    "    Computes the correlation ratio (η²) for a categorical feature \n",
    "    against a continuous target.\n",
    "    \"\"\"\n",
    "    unique_categories = np.unique(categories)\n",
    "    overall_mean = np.mean(values)\n",
    "    \n",
    "    # Compute between-group variance\n",
    "    between_group_var = sum(len(values[categories == cat]) * (np.mean(values[categories == cat]) - overall_mean)**2 \n",
    "                            for cat in unique_categories)\n",
    "    \n",
    "    # Compute total variance\n",
    "    total_var = np.sum((values - overall_mean) ** 2)\n",
    "    \n",
    "    return between_group_var / total_var if total_var > 0 else 0\n",
    "\n",
    "# Apply to all categorical variables\n",
    "categorical_cols = combined_data.select_dtypes(include=['object', 'category']).columns\n",
    "eta_squared_results = {col: correlation_ratio(combined_data[col], combined_data['Popularity']) for col in categorical_cols}\n",
    "\n",
    "# Display sorted results\n",
    "print(pd.Series(eta_squared_results).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metric Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
